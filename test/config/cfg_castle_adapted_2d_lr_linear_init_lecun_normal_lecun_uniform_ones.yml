# NN_Creation
# cfg_castle_adapted.yml
---
documentation:
  description: Options (specifications) for the "NN_Creation" script.

  authors:
    - iglesias-suarez_fernando
    - solino-fernandez_breixo

  maintainer:
    - iglesias-suarez_fernando
    - solino-fernandez_breixo

  references:
    - acknow_project

  projects:
    - usmile


# Common
# ======
# Note: Specify all directories/files from the project root
# Specifications
analysis: 'single' # 'single': gridpoints individually;
# 'concat': gridpoints contatenated into a
#           single time-series;
spcam_parents: [ 'ps', 'lhflx' ] # [ 'tbp','qbp','vbp','ps','solin','shflx','lhflx' ]
spcam_children: [ 'flnt', 'prect' ] # [ 'tphystnd','phq','fsns','flns','fsnt','flnt','prect' ]
# PCMCI. independence_test : "parcorr"
# Correlation. independence_test : "pearsonr"
# PCA. independence_test : "pca"
independence_test: "None" # todo: If PCA, the code doesn't work because of l. 21 in neural_networks/data_generator.py: if setup.ind_test_name == "pca":
pc_alphas: [ 0.01 ] # [0.001,0.01,0.1]; [0.01,0.05]
region: [ [ -90,90 ] , [ 0.,359. ] ]
lim_levels: False
# Model levels : [3.64, 7.59, 14.36, 24.61, 38.27, 54.6, 72.01, 87.82, 103.32, 121.55, 142.99, 168.23, 197.91, 232.83, 273.91, 322.24, 379.1, 445.99, 524.69, 609.78, 691.39, 763.4, 820.86, 859.53, 887.02, 912.64, 936.2, 957.49, 976.33, 992.56]
target_levels: False # [197.91] # False
# Rasp. TB: "./SPCAM_Rasp_causal_links_3mth"; "./SPCAM_Rasp_causal_links_3mth_v2";
#           "./SPCAM_Rasp_causal_links_3mth_pearsonr_v2"
output_folder: "./SPCAM_Rasp_causal_links_3mth_v2"
plots_folder: "plots"
verbosity: 1
output_file_pattern:
  single: "{var_name}_{level}_lat-{lat}_lon-{lon}_{ind_test}_{experiment}.obj"
  concat: "{var_name}_{level}_{lat1}-{lat2}_{lon1}-{lon2}_{ind_test}_{experiment}.obj"
## DATASETS. 
# Tom's: SPCAM_tb_recons; Aqua_0K_t-dt_recons
data_folder: "./SPCAM_tb_recons"
# Tom's. Rasp:      2021_09_02_TRAIN_For_Nando; 
experiment: "2021_09_02_TRAIN_For_Nando"
shifting: 0 # 0 (no shifting); 1 (output t-1)


# Aggregated analysis
# ===================
thresholds: [ .59 ]
area_weighted: True # True; False
pdf: True # True; False
aggregate_folder: "./aggregate_pdf"
plot_file_pattern:
  single: "{var_name}_{level}_lat{lat}_lon{lon}_a{pc_alpha}_{ind_test}_{experiment}.png"
  concat: "{var_name}_{level}_{lat1}-{lat2}_{lon1}-{lon2}_a{pc_alpha}_{ind_test}_{experiment}.png"


# Neural Network configuration
# ============================

nn_type: "CASTLEAdapted" # "all"; SingleNN"; "CausalSingleNN"; "CorrSingleNN"; "pcaNN"; "CASTLEOriginal" ; "CASTLEAdapted"

# Paths are relative to project root
nn_output_path: test/output/models_castle

input_order: [ ps, lhflx ] # [ qbp, tbp, vbp, ps, solin, shflx, lhflx ]
output_order: [ flnt, prect ] # [ phq, tphystnd, fsnt, fsns, flnt, flns, prect ]

hidden_layers: [ 32, 32 ]  # [ 256,256,256,256,256,256,256,256,256 ]
activation: ReLU # LeakyReLU. Use ReLU as in original CASTLE implementation


# Training configuration
# ----------------------
## DATASETS.
# Tom's: SPCAM_tb_prepoc
train_data_folder: "test/test_data/"  #"./SPCAM_tb_preproc", "test/test_data/"
# Tom's. Case: TRAIN/VALID. Rasp: 2021_09_02_TRAIN_For_Nando_shuffle.nc
#                                 2021_09_02_VALID_For_Nando.nc
train_data_fn: 2021_09_02_TRAIN_For_Nando_shuffle_perc0-0001.nc  # 2021_09_02_TRAIN_For_Nando_shuffle.nc
valid_data_fn: 2021_09_02_VALID_For_Nando_perc0-0002.nc  #2021_09_02_VALID_For_Nando.nc
epochs: 2
train_verbose: 1 # 0:Silent; 1:Continuous update; 2:Summary on epochs
tensorboard_folder: test/output/tensorboard

# From Tom https://github.com/tbeucler/CBRAIN-CAM/tree/master/notebooks/tbeucler_devlog/UW_DATA
normalization_folder: "test/test_data/"  #./SPCAM_tb_preproc, "test/test_data/"
normalization_fn: 001_norm_for_tb_dataset.nc

input_sub: mean
input_div: maxrs
out_scale_dict_folder: ./nn_config/scale_dicts/ # ./nn_config/scale_dicts/
out_scale_dict_fn: 002_pnas_scaling.pkl
batch_size: 256  #1024

# Learning Rate Scheduler
init_lr: 0.001 # From train.py (default)
## Exponential schedule (original Rasp et al.)
#lr_schedule: "exponential"
#step_lr: 3 # From 006_8col_pnas_exact.yml
#divide_lr: 5 # From train.py (default)

## Plateau schedule
#lr_schedule: "plateau"
#monitor: "val_loss"
#factor: 0.1
#patience: 10
#min_lr: 0

# Linear schedule
lr_schedule: "linear"
decay_steps: 2 # use number of epochs for constant decay
end_lr: 1e-8

## Cosine schedule
#lr_schedule: "cosine"
#decay_steps: 2 # use number of epochs for constant decay
#cosine_alpha: 0.0
#warmup_steps: 0

# Early Stopping
train_patience: 5 # TODO: This number was chosen arbitrarily


# CASTLEAdapted
# ===================
rho: 1.0
alpha: 1.0
lambda_prediction: 1.0
lambda_sparsity: 1.0
lambda_acyclicity: 1.0
lambda_reconstruction: 1.0
acyclicity_constraint: "NOTEARS" # DAGMA, NOTEARS
relu_alpha: 0.3
distribute_strategy: "mirrored" # mirrored, multi_worker_mirrored or nothing for normal training
additional_val_datasets:
  - { name: "test_1", data: "test/test_data/2021_09_02_TEST_For_Nando_shuffle_perc0-0002.nc" }
  - { name: "test_2", data: "test/test_data/2021_09_02_TEST_For_Nando_shuffle_perc0-0002.nc" }

# Input layers kernel initializer
#kernel_initializer_input_layers: "RandomNormal"
#input_init_random_normal_mean: 0.0
#input_init_random_normal_std: 0.01

#kernel_initializer_input_layers: "RandomUniform"
#input_init_random_uniform_min_val: 0.0
#input_init_random_uniform_max_val: 1.0
#
#kernel_initializer_input_layers: "VarianceScaling"
#input_init_variance_scaling_scale: 1.0
#input_init_variance_scaling_mode: "fan_in"
#input_init_variance_scaling_distribution: "truncated_normal"
#
kernel_initializer_input_layers: "LecunNormal"
#kernel_initializer_input_layers: "LecunUniform"


# Hidden layers kernel initializer
#kernel_initializer_hidden_layers: "RandomNormal"
#hidden_init_random_normal_mean: 0.0
#hidden_init_random_normal_std: 0.01

#kernel_initializer_hidden_layers: "RandomUniform"
#hidden_output_init_random_uniform_min_val: 0.0
#hidden_output_init_random_uniform_max_val: 1.0
#
#kernel_initializer_hidden_layers: "GlorotUniform"
#kernel_initializer_hidden_layers: "GlorotNormal"
#
#kernel_initializer_hidden_layers: "LecunNormal"
kernel_initializer_hidden_layers: "LecunUniform"
#
#kernel_initializer_hidden_layers: "HeNormal"
#kernel_initializer_hidden_layers: "HeUniform"

# Output layers kernel initializer
#kernel_initializer_output_layers: "RandomNormal"
#output_init_random_normal_mean: 0.0
#output_init_random_normal_std: 0.01

#kernel_initializer_output_layers: "RandomUniform"
#output_output_init_random_uniform_min_val: 0.0
#output_output_init_random_uniform_max_val: 1.0
#
#kernel_initializer_output_layers: "GlorotUniform"
#kernel_initializer_output_layers: "GlorotNormal"
#
#kernel_initializer_output_layers: "LecunNormal"
#kernel_initializer_output_layers: "LecunUniform"
#
#kernel_initializer_output_layers: "HeNormal"
#kernel_initializer_output_layers: "HeUniform"

kernel_initializer_output_layers: "Ones"

# Diagnostic configuration
# ----------------------
## DATASETS.
# Gunnar's: SPCAM_gb_prepoc; Tom's: SPCAM_tb_preproc
# Tom's: SPCAM_tb_prepoc; Aqua_Generalization_Test_Sets
test_data_folder: "test/test_data/" # "./SPCAM_tb_preproc"
# Gunnar's. Train (year/month): 002_train_1_<year/month>.nc 002_train_1_<year/month>_shuffle.nc
#           Valid (year/month): 000_valid_1_<year/month>.nc
# Tom's. Case: TRAIN/VALID. Rasp: 2021_09_02_TEST_For_Nando_shuffle.nc
#                                 2021_09_02_TEST_For_Nando.nc
#                          Gener: 2022_02_07_TEST_For_Nando_m4K.nc; 2022_02_07_TEST_For_Nando_p4K.nc
#                          ClInv: 2021_09_03_TEST_For_Nando_ClInv_shuffle.nc
#                                 2021_09_03_TEST_For_Nando_ClInv.nc
test_data_fn: 2021_09_02_TEST_For_Nando_shuffle_perc0-0001.nc # 2021_09_02_VALID_For_Nando.nc #
# Diagnostics
diagnostics: [ 'map' ]  # 'map'
diagnostics_time: [ 'mean' ] # snapshot: int; time-mean: 'mean'
